{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0feb13e4",
      "metadata": {
        "id": "0feb13e4"
      },
      "source": [
        "Importing Images From Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98102b82",
      "metadata": {
        "id": "98102b82"
      },
      "outputs": [],
      "source": [
        "# from pickleshare import Path\n",
        "from pathlib import Path\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "root_img_path = Path(kagglehub.dataset_download(\"uraninjo/augmented-alzheimer-mri-dataset\"))\n",
        "\n",
        "# print(\"Path to dataset files:\", PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a29eba",
      "metadata": {
        "id": "e3a29eba"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ec7f8e",
      "metadata": {
        "id": "c5ec7f8e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5175e3",
      "metadata": {
        "id": "8f5175e3"
      },
      "source": [
        "Seed Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb33d234",
      "metadata": {
        "id": "fb33d234"
      },
      "outputs": [],
      "source": [
        "SEED = 67\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "765fcb41",
      "metadata": {
        "id": "765fcb41"
      },
      "source": [
        "GLOBAL VARS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05adae94",
      "metadata": {
        "id": "05adae94"
      },
      "outputs": [],
      "source": [
        "IMAGES_PATH = root_img_path / \"OriginalDataset\"\n",
        "IMG_SIZE = (299,299) # the image size that inceptionresnetv2 uses\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "NUM_CLASSES = 4\n",
        "EPOCHS_HEAD = 70\n",
        "# EPOCHS_FT = 20\n",
        "\n",
        "LR_HEAD = 5e-5\n",
        "# LR_FT = 2e-5\n",
        "# FINE_TUNE_TOP_LAYERS = 20\n",
        "\n",
        "BEST_WEIGHTS_PATH = \"best_weights.weights.h5\"\n",
        "# where to save the best weights from the training epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d2f95f",
      "metadata": {
        "id": "28d2f95f"
      },
      "source": [
        "Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fdb37cb",
      "metadata": {
        "id": "5fdb37cb",
        "outputId": "11b0582b-d2cb-453a-88ee-6acda39319c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6400 files belonging to 4 classes.\n",
            "Class counts total: [ 896   64 3200 2240]\n"
          ]
        }
      ],
      "source": [
        "# load in all the files and class names before splitting\n",
        "all_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    IMAGES_PATH,\n",
        "    image_size=IMG_SIZE,\n",
        "    color_mode=\"grayscale\",   # reads in images as grayscale --> convert to rgb later\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False             # just for file listing\n",
        ")\n",
        "class_names = all_ds.class_names\n",
        "assert len(class_names) == NUM_CLASSES\n",
        "\n",
        "paths = np.array(all_ds.file_paths)\n",
        "labels = np.array([class_names.index(Path(p).parent.name) for p in paths], dtype=np.int32)\n",
        "\n",
        "print(\"Class counts total:\", np.bincount(labels, minlength=NUM_CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f192f9",
      "metadata": {
        "id": "61f192f9",
        "outputId": "6b08091d-980e-46b0-d5c7-58b297e16eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train counts: [ 628   44 2240 1568]\n",
            "Val counts:   [134  10 480 336]\n",
            "Test counts:  [134  10 480 336]\n"
          ]
        }
      ],
      "source": [
        "# stratified split (70,15,15)\n",
        "def stratified_split(paths, y, val_frac=0.15, test_frac=0.15, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(paths))\n",
        "    tr, va, te = [], [], []\n",
        "    # go through each class and allocate a random number of images to training, validation and testing\n",
        "    # based off the fraction split\n",
        "    for c in range(NUM_CLASSES):\n",
        "        c_idx = idx[y == c]\n",
        "        rng.shuffle(c_idx)\n",
        "        n = len(c_idx)\n",
        "        n_te = int(round(n * test_frac))\n",
        "        n_va = int(round(n * val_frac))\n",
        "        te.append(c_idx[:n_te])\n",
        "        va.append(c_idx[n_te:n_te+n_va])\n",
        "        tr.append(c_idx[n_te+n_va:])\n",
        "    tr = np.concatenate(tr); va = np.concatenate(va); te = np.concatenate(te)\n",
        "    rng.shuffle(tr); rng.shuffle(va); rng.shuffle(te)\n",
        "    return paths[tr], y[tr], paths[va], y[va], paths[te], y[te]\n",
        "\n",
        "train_paths, train_y, val_paths, val_y, test_paths, test_y = stratified_split(paths, labels, seed=SEED)\n",
        "\n",
        "# display the number of images per class for each type of set (train, val, test)\n",
        "print(\"Train counts:\", np.bincount(train_y, minlength=NUM_CLASSES))\n",
        "print(\"Val counts:  \", np.bincount(val_y, minlength=NUM_CLASSES))\n",
        "print(\"Test counts: \", np.bincount(test_y, minlength=NUM_CLASSES))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9c3289e",
      "metadata": {
        "id": "a9c3289e"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a1aa46",
      "metadata": {
        "id": "44a1aa46"
      },
      "outputs": [],
      "source": [
        "# data augmentation: keep minimal\n",
        "aug = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(0.05, seed=SEED),\n",
        "    tf.keras.layers.RandomTranslation(0.05, 0.05, seed=SEED),\n",
        "    tf.keras.layers.RandomZoom(0.05, seed=SEED),\n",
        "    # no random horizontal flip because that just doesn't make sense anatomically\n",
        "], name = \"aug\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe74354",
      "metadata": {
        "id": "cbe74354"
      },
      "outputs": [],
      "source": [
        "def decode_and_preprocess(path, label, training=False):\n",
        "    img_bytes = tf.io.read_file(path) # read in the images as raw bytes\n",
        "    img = tf.io.decode_image(img_bytes, channels=1, expand_animations=False) # decode into a image tensor\n",
        "    img.set_shape([None, None, 1]) # gives tensorflow a set shape\n",
        "    img = tf.image.resize(img, IMG_SIZE) # resizes the image to the img_size (check global vars)\n",
        "    img = tf.image.grayscale_to_rgb(img) # convert to rgb (what inception expects)\n",
        "    img = tf.cast(img, tf.float32) # convert for data aug and preprocessing\n",
        "    # apply augmentation only for training set\n",
        "    if training:\n",
        "        img = aug(img, training=True)\n",
        "    img = preprocess_input(img)  # InceptionResNetV2 expects this\n",
        "    return img, label\n",
        "\n",
        "def make_ds(paths, y, training=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, y))\n",
        "    # shuffle only for training to improve generalization\n",
        "    # buffer size is capped at 4000 to limit memory use on large datasets\n",
        "    if training:\n",
        "        ds = ds.shuffle(min(len(paths), 4000), seed=SEED, reshuffle_each_iteration=True)\n",
        "    # map paths --> decoded & preprocessed image tensors (parallelized for speed)\n",
        "    ds = ds.map(lambda p, l: decode_and_preprocess(p, l, training),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "    # overlap CPU preprocessing with GPU training to reduce input bottlenecks\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# create all the datasets (preprocessing) + data aug only for training\n",
        "train_ds = make_ds(train_paths, train_y, training=True)\n",
        "val_ds   = make_ds(val_paths,   val_y,   training=False)\n",
        "test_ds  = make_ds(test_paths,  test_y,  training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3c6574",
      "metadata": {
        "id": "5b3c6574",
        "outputId": "cffc75fe-35d1-4f94-bcaa-f4af3eb3896f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class_weight: {0: 1.961783528327942, 1: 25.454545974731445, 2: 0.4699999988079071, 3: 0.9071428775787354}\n"
          ]
        }
      ],
      "source": [
        "# since the classes as really imbalanced, we want to reweight the classes\n",
        "counts = np.bincount(train_y, minlength=NUM_CLASSES).astype(np.float32)\n",
        "total = counts.sum()\n",
        "base_w = total / (NUM_CLASSES * counts)\n",
        "# since the base weights won't give us a good enough accuracy, precision or recall,\n",
        "# we choose to slightly alter the weights a little bit\n",
        "m = np.ones(NUM_CLASSES, dtype=np.float32)\n",
        "m[0] *= 1.10\n",
        "# m[1] *= 0.95\n",
        "m[2] *= 0.94\n",
        "m[3] *= 1.27\n",
        "w = base_w*m\n",
        "# w /= np.mean(w)\n",
        "\n",
        "class_weight = {i: float(w[i]) for i in range(NUM_CLASSES)}\n",
        "print(\"class_weight:\", class_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd60d3b",
      "metadata": {
        "id": "cbd60d3b"
      },
      "source": [
        "Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e54c6d",
      "metadata": {
        "id": "06e54c6d"
      },
      "outputs": [],
      "source": [
        "base=tf.keras.applications.InceptionResNetV2(\n",
        "    include_top = False,\n",
        "    weights = \"imagenet\",\n",
        "    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3), # size of 2D input image plus RGB (3)\n",
        "    pooling = None,\n",
        ")\n",
        "\n",
        "inputs = tf.keras.Input(shape = (IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "x = base(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x) # helps prevent overfitting\n",
        "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "base.trainable = False\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "874c75ed",
      "metadata": {
        "id": "874c75ed"
      },
      "source": [
        "Train Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0deb9b8d",
      "metadata": {
        "id": "0deb9b8d"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=BEST_WEIGHTS_PATH,\n",
        "    monitor=\"val_loss\",        # or \"val_acc\"\n",
        "    mode=\"min\",                # \"min\" for val_loss, \"max\" for val_acc\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6701db21",
      "metadata": {
        "id": "6701db21",
        "outputId": "de0ea0c3-a07b-435e-fbb0-ea0be8a3efee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.3892 - loss: 1.4424\n",
            "Epoch 1: val_loss improved from None to 0.98547, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 1: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 321ms/step - acc: 0.4817 - loss: 1.1654 - val_acc: 0.5427 - val_loss: 0.9855\n",
            "Epoch 2/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - acc: 0.6372 - loss: 0.7436\n",
            "Epoch 2: val_loss improved from 0.98547 to 0.80310, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 2: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 273ms/step - acc: 0.6594 - loss: 0.6662 - val_acc: 0.6500 - val_loss: 0.8031\n",
            "Epoch 3/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - acc: 0.7721 - loss: 0.4015\n",
            "Epoch 3: val_loss improved from 0.80310 to 0.57881, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 3: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 274ms/step - acc: 0.7944 - loss: 0.3939 - val_acc: 0.7719 - val_loss: 0.5788\n",
            "Epoch 4/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - acc: 0.8712 - loss: 0.2421\n",
            "Epoch 4: val_loss improved from 0.57881 to 0.43876, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 4: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - acc: 0.8777 - loss: 0.2361 - val_acc: 0.8219 - val_loss: 0.4388\n",
            "Epoch 5/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - acc: 0.9227 - loss: 0.1498\n",
            "Epoch 5: val_loss did not improve from 0.43876\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 247ms/step - acc: 0.9275 - loss: 0.1429 - val_acc: 0.7260 - val_loss: 0.9125\n",
            "Epoch 6/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - acc: 0.9562 - loss: 0.0910\n",
            "Epoch 6: val_loss did not improve from 0.43876\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 244ms/step - acc: 0.9520 - loss: 0.0973 - val_acc: 0.8073 - val_loss: 0.6063\n",
            "Epoch 7/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9546 - loss: 0.0849\n",
            "Epoch 7: val_loss did not improve from 0.43876\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9578 - loss: 0.0806 - val_acc: 0.8562 - val_loss: 0.4459\n",
            "Epoch 8/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9676 - loss: 0.0666\n",
            "Epoch 8: val_loss improved from 0.43876 to 0.27856, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 8: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - acc: 0.9701 - loss: 0.0563 - val_acc: 0.9073 - val_loss: 0.2786\n",
            "Epoch 9/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9791 - loss: 0.0408\n",
            "Epoch 9: val_loss did not improve from 0.27856\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9739 - loss: 0.0521 - val_acc: 0.8208 - val_loss: 0.6530\n",
            "Epoch 10/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9781 - loss: 0.0428\n",
            "Epoch 10: val_loss did not improve from 0.27856\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9810 - loss: 0.0410 - val_acc: 0.8281 - val_loss: 0.5998\n",
            "Epoch 11/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9749 - loss: 0.0648\n",
            "Epoch 11: val_loss did not improve from 0.27856\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9766 - loss: 0.0663 - val_acc: 0.8729 - val_loss: 0.4797\n",
            "Epoch 12/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9857 - loss: 0.0499\n",
            "Epoch 12: val_loss improved from 0.27856 to 0.22032, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 12: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - acc: 0.9875 - loss: 0.0383 - val_acc: 0.9385 - val_loss: 0.2203\n",
            "Epoch 13/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9872 - loss: 0.0319\n",
            "Epoch 13: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9862 - loss: 0.0370 - val_acc: 0.8865 - val_loss: 0.3749\n",
            "Epoch 14/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9749 - loss: 0.0359\n",
            "Epoch 14: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9830 - loss: 0.0265 - val_acc: 0.8417 - val_loss: 0.6277\n",
            "Epoch 15/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9871 - loss: 0.0287\n",
            "Epoch 15: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9857 - loss: 0.0373 - val_acc: 0.9292 - val_loss: 0.2445\n",
            "Epoch 16/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9844 - loss: 0.0327\n",
            "Epoch 16: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9815 - loss: 0.0390 - val_acc: 0.8938 - val_loss: 0.3532\n",
            "Epoch 17/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9859 - loss: 0.0331\n",
            "Epoch 17: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9875 - loss: 0.0269 - val_acc: 0.9292 - val_loss: 0.2696\n",
            "Epoch 18/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9898 - loss: 0.0203\n",
            "Epoch 18: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9879 - loss: 0.0248 - val_acc: 0.8781 - val_loss: 0.4435\n",
            "Epoch 19/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9902 - loss: 0.0218\n",
            "Epoch 19: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9897 - loss: 0.0222 - val_acc: 0.9229 - val_loss: 0.2840\n",
            "Epoch 20/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9956 - loss: 0.0124\n",
            "Epoch 20: val_loss did not improve from 0.22032\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9926 - loss: 0.0164 - val_acc: 0.9365 - val_loss: 0.2524\n",
            "Epoch 21/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9958 - loss: 0.0100\n",
            "Epoch 21: val_loss improved from 0.22032 to 0.13006, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 21: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - acc: 0.9958 - loss: 0.0088 - val_acc: 0.9604 - val_loss: 0.1301\n",
            "Epoch 22/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9911 - loss: 0.0189\n",
            "Epoch 22: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9904 - loss: 0.0237 - val_acc: 0.9021 - val_loss: 0.3701\n",
            "Epoch 23/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9903 - loss: 0.0210\n",
            "Epoch 23: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9917 - loss: 0.0183 - val_acc: 0.9427 - val_loss: 0.1567\n",
            "Epoch 24/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9860 - loss: 0.0284\n",
            "Epoch 24: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9902 - loss: 0.0214 - val_acc: 0.9438 - val_loss: 0.2597\n",
            "Epoch 25/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9922 - loss: 0.0196\n",
            "Epoch 25: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9924 - loss: 0.0159 - val_acc: 0.8792 - val_loss: 0.5126\n",
            "Epoch 26/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9958 - loss: 0.0124\n",
            "Epoch 26: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9935 - loss: 0.0180 - val_acc: 0.9406 - val_loss: 0.1934\n",
            "Epoch 27/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9839 - loss: 0.0313\n",
            "Epoch 27: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9882 - loss: 0.0281 - val_acc: 0.8813 - val_loss: 0.4669\n",
            "Epoch 28/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9886 - loss: 0.0284\n",
            "Epoch 28: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9895 - loss: 0.0242 - val_acc: 0.9271 - val_loss: 0.2168\n",
            "Epoch 29/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9871 - loss: 0.0348\n",
            "Epoch 29: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9871 - loss: 0.0384 - val_acc: 0.9375 - val_loss: 0.1920\n",
            "Epoch 30/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9880 - loss: 0.0277\n",
            "Epoch 30: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9904 - loss: 0.0206 - val_acc: 0.9375 - val_loss: 0.2300\n",
            "Epoch 31/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9967 - loss: 0.0067\n",
            "Epoch 31: val_loss did not improve from 0.13006\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9953 - loss: 0.0133 - val_acc: 0.9250 - val_loss: 0.3320\n",
            "Epoch 32/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9912 - loss: 0.0148\n",
            "Epoch 32: val_loss improved from 0.13006 to 0.10822, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 32: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 267ms/step - acc: 0.9926 - loss: 0.0122 - val_acc: 0.9698 - val_loss: 0.1082\n",
            "Epoch 33/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9970 - loss: 0.0095\n",
            "Epoch 33: val_loss did not improve from 0.10822\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9984 - loss: 0.0050 - val_acc: 0.9563 - val_loss: 0.1589\n",
            "Epoch 34/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9979 - loss: 0.0080\n",
            "Epoch 34: val_loss improved from 0.10822 to 0.08031, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 34: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - acc: 0.9964 - loss: 0.0118 - val_acc: 0.9719 - val_loss: 0.0803\n",
            "Epoch 35/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9937 - loss: 0.0127\n",
            "Epoch 35: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9944 - loss: 0.0111 - val_acc: 0.9104 - val_loss: 0.2900\n",
            "Epoch 36/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9960 - loss: 0.0071\n",
            "Epoch 36: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9964 - loss: 0.0079 - val_acc: 0.9656 - val_loss: 0.1118\n",
            "Epoch 37/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9917 - loss: 0.0193\n",
            "Epoch 37: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9888 - loss: 0.0355 - val_acc: 0.8969 - val_loss: 0.4936\n",
            "Epoch 38/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9797 - loss: 0.0882\n",
            "Epoch 38: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9790 - loss: 0.0696 - val_acc: 0.8802 - val_loss: 0.4464\n",
            "Epoch 39/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9960 - loss: 0.0106\n",
            "Epoch 39: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9942 - loss: 0.0117 - val_acc: 0.9438 - val_loss: 0.1518\n",
            "Epoch 40/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9969 - loss: 0.0071\n",
            "Epoch 40: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9971 - loss: 0.0076 - val_acc: 0.9625 - val_loss: 0.1252\n",
            "Epoch 41/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9994 - loss: 0.0035\n",
            "Epoch 41: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9987 - loss: 0.0042 - val_acc: 0.9125 - val_loss: 0.2935\n",
            "Epoch 42/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9990 - loss: 0.0030\n",
            "Epoch 42: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9982 - loss: 0.0032 - val_acc: 0.9583 - val_loss: 0.1530\n",
            "Epoch 43/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9993 - loss: 0.0025\n",
            "Epoch 43: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9991 - loss: 0.0022 - val_acc: 0.9719 - val_loss: 0.0949\n",
            "Epoch 44/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9976 - loss: 0.0054\n",
            "Epoch 44: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9964 - loss: 0.0118 - val_acc: 0.8813 - val_loss: 0.4879\n",
            "Epoch 45/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9883 - loss: 0.0232\n",
            "Epoch 45: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9868 - loss: 0.0284 - val_acc: 0.8771 - val_loss: 0.4505\n",
            "Epoch 46/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9880 - loss: 0.0257\n",
            "Epoch 46: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9866 - loss: 0.0290 - val_acc: 0.9302 - val_loss: 0.3279\n",
            "Epoch 47/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9905 - loss: 0.0220\n",
            "Epoch 47: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9913 - loss: 0.0211 - val_acc: 0.9615 - val_loss: 0.1260\n",
            "Epoch 48/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9965 - loss: 0.0101\n",
            "Epoch 48: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9971 - loss: 0.0093 - val_acc: 0.9427 - val_loss: 0.2219\n",
            "Epoch 49/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9939 - loss: 0.0115\n",
            "Epoch 49: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9929 - loss: 0.0201 - val_acc: 0.9740 - val_loss: 0.0868\n",
            "Epoch 50/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9943 - loss: 0.0187\n",
            "Epoch 50: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9933 - loss: 0.0177 - val_acc: 0.9406 - val_loss: 0.1783\n",
            "Epoch 51/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9963 - loss: 0.0083\n",
            "Epoch 51: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9960 - loss: 0.0082 - val_acc: 0.9656 - val_loss: 0.1006\n",
            "Epoch 52/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9976 - loss: 0.0051\n",
            "Epoch 52: val_loss did not improve from 0.08031\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9967 - loss: 0.0058 - val_acc: 0.9646 - val_loss: 0.1154\n",
            "Epoch 53/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9983 - loss: 0.0039\n",
            "Epoch 53: val_loss improved from 0.08031 to 0.06951, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 53: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - acc: 0.9984 - loss: 0.0042 - val_acc: 0.9760 - val_loss: 0.0695\n",
            "Epoch 54/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9975 - loss: 0.0058\n",
            "Epoch 54: val_loss improved from 0.06951 to 0.06266, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 54: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - acc: 0.9973 - loss: 0.0056 - val_acc: 0.9781 - val_loss: 0.0627\n",
            "Epoch 55/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - acc: 0.9981 - loss: 0.0032\n",
            "Epoch 55: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9991 - loss: 0.0021 - val_acc: 0.9719 - val_loss: 0.0909\n",
            "Epoch 56/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9998 - loss: 0.0026\n",
            "Epoch 56: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9993 - loss: 0.0029 - val_acc: 0.9729 - val_loss: 0.0660\n",
            "Epoch 57/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9958 - loss: 0.0097\n",
            "Epoch 57: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9931 - loss: 0.0153 - val_acc: 0.9656 - val_loss: 0.1484\n",
            "Epoch 58/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9908 - loss: 0.0161\n",
            "Epoch 58: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9937 - loss: 0.0119 - val_acc: 0.9656 - val_loss: 0.0966\n",
            "Epoch 59/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9964 - loss: 0.0068\n",
            "Epoch 59: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9967 - loss: 0.0077 - val_acc: 0.8802 - val_loss: 0.8358\n",
            "Epoch 60/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9932 - loss: 0.0153\n",
            "Epoch 60: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9937 - loss: 0.0127 - val_acc: 0.9583 - val_loss: 0.1294\n",
            "Epoch 61/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9970 - loss: 0.0063\n",
            "Epoch 61: val_loss did not improve from 0.06266\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9978 - loss: 0.0053 - val_acc: 0.9750 - val_loss: 0.0710\n",
            "Epoch 62/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9991 - loss: 0.0015\n",
            "Epoch 62: val_loss improved from 0.06266 to 0.04945, saving model to best_weights.weights.h5\n",
            "\n",
            "Epoch 62: finished saving model to best_weights.weights.h5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - acc: 0.9993 - loss: 0.0013 - val_acc: 0.9823 - val_loss: 0.0495\n",
            "Epoch 63/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9995 - loss: 0.0010    \n",
            "Epoch 63: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - acc: 0.9991 - loss: 0.0017 - val_acc: 0.9719 - val_loss: 0.0838\n",
            "Epoch 64/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9987 - loss: 0.0031\n",
            "Epoch 64: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9982 - loss: 0.0035 - val_acc: 0.9396 - val_loss: 0.2577\n",
            "Epoch 65/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9924 - loss: 0.0186\n",
            "Epoch 65: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9884 - loss: 0.0359 - val_acc: 0.9229 - val_loss: 0.4024\n",
            "Epoch 66/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9841 - loss: 0.0448\n",
            "Epoch 66: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9862 - loss: 0.0376 - val_acc: 0.9333 - val_loss: 0.2864\n",
            "Epoch 67/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9926 - loss: 0.0153\n",
            "Epoch 67: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9929 - loss: 0.0135 - val_acc: 0.9615 - val_loss: 0.1099\n",
            "Epoch 68/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9959 - loss: 0.0084\n",
            "Epoch 68: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9962 - loss: 0.0073 - val_acc: 0.9698 - val_loss: 0.0906\n",
            "Epoch 69/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - acc: 0.9970 - loss: 0.0046\n",
            "Epoch 69: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9975 - loss: 0.0046 - val_acc: 0.9583 - val_loss: 0.2371\n",
            "Epoch 70/70\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - acc: 0.9938 - loss: 0.0326\n",
            "Epoch 70: val_loss did not improve from 0.04945\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 241ms/step - acc: 0.9902 - loss: 0.0433 - val_acc: 0.9271 - val_loss: 0.3033\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR_HEAD, clipnorm=1.0),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), # because labels are ints and not one-hot encoded vectors\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_HEAD,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=[checkpoint_cb] # ensures we only save the best performing set of weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6939a7",
      "metadata": {
        "id": "ba6939a7",
        "outputId": "13adfc4a-296f-4d43-eeed-6d357a058a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - acc: 0.9875 - loss: 0.0351\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.035124555230140686, 0.987500011920929]"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_weights(BEST_WEIGHTS_PATH) # uses the best weights for evaluation\n",
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5592915",
      "metadata": {
        "id": "c5592915"
      },
      "source": [
        "Evaluation and Confusion Matrix and Per-Class Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3cea3a",
      "metadata": {
        "id": "3d3cea3a",
        "outputId": "115a6340-b779-4f53-8229-02ecec63a831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "VAL confusion matrix (rows=true, cols=pred):\n",
            " [[134   0   0   0]\n",
            " [  0  10   0   0]\n",
            " [  1   0 469  10]\n",
            " [  0   0   6 330]]\n",
            "\n",
            "TEST confusion matrix (rows=true, cols=pred):\n",
            " [[134   0   0   0]\n",
            " [  0  10   0   0]\n",
            " [  0   0 475   5]\n",
            " [  1   0   6 329]]\n",
            "\n",
            "VAL per-class:\n",
            "  MildDemented  P=0.993  R=1.000  F1=0.996  n=134\n",
            "  ModerateDemented  P=1.000  R=1.000  F1=1.000  n=10\n",
            "   NonDemented  P=0.987  R=0.977  F1=0.982  n=480\n",
            "  VeryMildDemented  P=0.971  R=0.982  F1=0.976  n=336\n",
            "  VAL Balanced Acc (macro recall): 0.99\n",
            "\n",
            "TEST per-class:\n",
            "  MildDemented  P=0.993  R=1.000  F1=0.996  n=134\n",
            "  ModerateDemented  P=1.000  R=1.000  F1=1.000  n=10\n",
            "   NonDemented  P=0.988  R=0.990  F1=0.989  n=480\n",
            "  VeryMildDemented  P=0.985  R=0.979  F1=0.982  n=336\n",
            "  TEST Balanced Acc (macro recall): 0.992\n"
          ]
        }
      ],
      "source": [
        "def predict_labels(ds):\n",
        "    probs = model.predict(ds, verbose=0)\n",
        "    return np.argmax(probs, axis=1), probs\n",
        "\n",
        "val_pred, _  = predict_labels(val_ds)\n",
        "test_pred, _ = predict_labels(test_ds)\n",
        "\n",
        "def confusion_matrix_np(y_true, y_pred, num_classes):\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        cm[int(t), int(p)] += 1\n",
        "    return cm\n",
        "\n",
        "cm_val  = confusion_matrix_np(val_y,  val_pred,  NUM_CLASSES)\n",
        "cm_test = confusion_matrix_np(test_y, test_pred, NUM_CLASSES)\n",
        "\n",
        "print(\"\\nVAL confusion matrix (rows=true, cols=pred):\\n\", cm_val)\n",
        "print(\"\\nTEST confusion matrix (rows=true, cols=pred):\\n\", cm_test)\n",
        "\n",
        "def per_class_report(cm, class_names):\n",
        "    # precision, recall, f1 per class\n",
        "    eps = 1e-9\n",
        "    report = []\n",
        "    for i, name in enumerate(class_names):\n",
        "        tp = cm[i, i]\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        precision = tp / (tp + fp + eps)\n",
        "        recall    = tp / (tp + fn + eps)\n",
        "        f1        = 2 * precision * recall / (precision + recall + eps)\n",
        "        support   = cm[i, :].sum()\n",
        "        report.append((name, precision, recall, f1, support))\n",
        "    bal_acc = np.mean([r[2] for r in report])  # macro recall\n",
        "    return report, bal_acc\n",
        "\n",
        "rep_val,  bal_val  = per_class_report(cm_val, class_names)\n",
        "rep_test, bal_test = per_class_report(cm_test, class_names)\n",
        "\n",
        "print(\"\\nVAL per-class:\")\n",
        "for name, p, r, f1, sup in rep_val:\n",
        "    print(f\"  {name:>12s}  P={p:.3f}  R={r:.3f}  F1={f1:.3f}  n={sup}\")\n",
        "print(\"  VAL Balanced Acc (macro recall):\", round(bal_val, 3))\n",
        "\n",
        "print(\"\\nTEST per-class:\")\n",
        "for name, p, r, f1, sup in rep_test:\n",
        "    print(f\"  {name:>12s}  P={p:.3f}  R={r:.3f}  F1={f1:.3f}  n={sup}\")\n",
        "print(\"  TEST Balanced Acc (macro recall):\", round(bal_test, 3))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}